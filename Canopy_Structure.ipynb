{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c646a8",
   "metadata": {},
   "source": [
    "# Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4938c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# ! pip install --user open3d # run if open3D is not installed, http://www.open3d.org/ (Zhou et al., 2018)\n",
    "# ! pip install --user scikit-spatial\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils_final import whole_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c32dc2",
   "metadata": {},
   "source": [
    "# Create result dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db336dfe-cc69-46a0-9a6a-b6a659d3faa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad(data, max_slices, pad_value=np.NAN):\n",
    "    \"\"\"\n",
    "    Create padding for dataframe where there is no tree slice at that height\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    data: \n",
    "        values of interest\n",
    "    max_slices:\n",
    "        maximum number of slices that make up a plot or individual tree\n",
    "    pad_value:\n",
    "        NAN if a tree doesn't reach the max height \n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    The correct amount of null values\n",
    "    \"\"\"    \n",
    "    return np.pad(data, (0,max_slices-len(data)), 'constant', constant_values=pad_value)\n",
    "\n",
    "\n",
    "def generate_df(file_name_list, value_list):\n",
    "    \"\"\"\n",
    "    Creates result dataframe with null values and names based on the file name \n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    file_name_list: \n",
    "        point cloud files (.pcd)\n",
    "    value_list:\n",
    "        LAI, leaf area density, or leaf angle values\n",
    "        \n",
    "    Returns\n",
    "    ----------------\n",
    "    Concatenated results dataframe of the appropriate species grouping\n",
    "    \"\"\"\n",
    "    max_slices = np.max([len(x) for x in value_list])\n",
    "    \n",
    "    value_array_padded = np.array([pad(x,max_slices) for x in value_list])\n",
    "    values_df = pd.DataFrame(value_array_padded,columns=[f\"slice_{x+1}\" for x in range(value_array_padded.shape[1])])    \n",
    "    \n",
    "    file_name_df = pd.DataFrame(\n",
    "        {\n",
    "            \"plot_name\":files_list,\n",
    "        }\n",
    "    )\n",
    "    file_name_df = file_name_df[\"plot_name\"].str.split(\"_\",n=3,expand=True)\n",
    "    file_name_df = file_name_df.drop(3,axis=1)\n",
    "\n",
    "    file_name_df.loc[file_name_df[2] == \"leaves\",2] = \"all\"\n",
    "    file_name_df.columns = [\"plot\",\"year\",\"species\"]\n",
    "    \n",
    "    return pd.concat([file_name_df,values_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626bfab1",
   "metadata": {},
   "source": [
    "# Specify input & output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb3c6a5-d606-4d46-9753-a418cdf0e1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_folder =  \"C:\\\\Users\\\\ANGELASEIBERT\\\\Desktop\\\\Python_Workspace\\\\leaf_pcd_files\\\\testing\\\\\" # where the leaf .pcd files are stored \n",
    "file_extension = \".pcd\"\n",
    "output_folder =  \"C:\\\\Users\\\\ANGELASEIBERT\\\\Desktop\\\\Python_Workspace\\\\leaf_pcd_files\\\\testing\\\\output\\\\\" # where the output csv should go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b200c",
   "metadata": {},
   "source": [
    "# Import the full workflow from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7e8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_final import whole_pipeline # save utils file and run this line to apply any utils updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4ebcf",
   "metadata": {},
   "source": [
    "# Run the full workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d8bb14-9ded-495a-ba4e-9bef4f50ee9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- plot4_2015_larch_leaves.pcd\n",
      "NOT WHOLE PLOT\n",
      "how many half meter slices: 13.0\n",
      "Slice Correction Factors: [0.0904020152610505, 0.20622116376906577, 0.28187204752856393, 0.3428476143895694, 0.36321084243959045, 0.3693582386373871, 0.3903613051058343, 0.46918265212630966, 0.42025898898486974, 0.40970635510595627, 0.48059263412381703, 0.44285345015145866, 0.4608425030414553]\n",
      "CF Standard Deviations: [0.11009686104828306, 0.08915333550937744, 0.04671351593737734, 0.011845844703880459, 0.026560023549997744, 0.03772239886330231, 0.06957297841762224, 0.11751606974773897, 0.13135789512708151, 0.11976399395167393, 0.21188898136143447, 0.13797865174680218, 0.18455308615236193]\n",
      "how many half meter slices for the second file: 13.0\n",
      "The LAD is: [0.006101076219324704, 0.008787317340418585, 0.008578837064875935, 0.008225090329644469, 0.007153409109666555, 0.010626465113938843, 0.008230036029864732, 0.013789033993522262, 0.009638449581366322, 0.008993731059725596, 0.01136400971378208, 0.011585694322590642, 0.004767263731784597]\n",
      "The LAI is: 0.11784041361050533\n",
      "---------- plot4_2015_leaves.pcd\n",
      "WHOLE PLOT\n",
      "how many half meter slices: 13.0\n",
      "Slice Correction Factors: [0.10553082129956406, 0.23419817809604562, 0.32403944832169645, 0.31243983722701507, 0.36875073438069855, 0.3625326060311557, 0.3439875082676447, 0.4210296461259995, 0.3559110985359825, 0.36247798643999657, 0.46790807457054556, 1.0261706190609012, 0.37487832868644744]\n",
      "CF Standard Deviations: [0.07913513348500972, 0.1006289809872473, 0.024967520008843558, 0.05572617736925923, 0.023576728483394226, 0.02868516231876227, 0.013313939917339599, 0.10600274946881115, 0.021271938165371516, 0.04444244974224367, 0.13190802325521195, 1.0049998653313623, 0.07293242583215918]\n",
      "how many half meter slices for the second file: 13.0\n",
      "The LAD is: [0.03288750056674108, 0.06706933951004045, 0.07324736824060274, 0.07454445275822313, 0.08520306086522908, 0.08219070179142866, 0.07064862308685492, 0.0931921219197228, 0.08397304750254406, 0.07301294448271037, 0.1297131443023256, 0.3127017608274544, 0.2478916287208798]\n",
      "The LAI is: 1.4262756945747572\n",
      "---------- plot4_2015_spruce_leaves.pcd\n",
      "NOT WHOLE PLOT\n",
      "how many half meter slices: 12.0\n",
      "Slice Correction Factors: [0.11013064066192957, 0.22254826098701713, 0.31964892477606, 0.3391703143642907, 0.38168246854197635, 0.37403163948089313, 0.37777156046186955, 0.41238233241352296, 0.40750656132231444, 0.39557797763812974, 0.37005094875343525, 0.37130746906239936]\n",
      "CF Standard Deviations: [0.07150316403641184, 0.0837385448281172, 0.03814353941231218, 0.010449159097903745, 0.03329655645725115, 0.06959102179224606, 0.07092348381186217, 0.11633705414173617, 0.09641433026618754, 0.03078533073195828, 0.056031788818004004, 0.04414051370375421]\n",
      "how many half meter slices for the second file: 13.0\n",
      "The LAD is: [0.027088824403843692, 0.0519994071381752, 0.06688605625185855, 0.07225261082887514, 0.08262890265063945, 0.0736357051289204, 0.0758095831124146, 0.0895946078345134, 0.09252900424411788, 0.06682447955736123, 0.07868263930640093, 0.16081311471553283]\n",
      "The LAI is: 0.9387449351726533\n"
     ]
    }
   ],
   "source": [
    "files_list = []\n",
    "LAI_list = []\n",
    "LAD_list = []\n",
    "allangles_list = []\n",
    "LA_correction_factors_list = []\n",
    "\n",
    "for file_1 in os.listdir(input_folder):\n",
    "    if file_1.endswith(file_extension):\n",
    "        files_list.append(file_1.split('.')[0])\n",
    "        \n",
    "        print(\"-\"*10, file_1)\n",
    "        number_words = len(file_1.split(\"_\"))\n",
    "\n",
    "        if number_words == 3:\n",
    "            print(\"WHOLE PLOT\")\n",
    "            whole_path_1 = input_folder+file_1\n",
    "            LAI,LAD,allangles,LA_correction_factors = whole_pipeline(whole_path_1,whole_path_1,visualize=False)\n",
    "        elif number_words == 4:\n",
    "            print(\"NOT WHOLE PLOT\")\n",
    "            # infer name of the file with the whole plot\n",
    "            file_1_split = file_1.split(\"_\")\n",
    "            file_1_split.pop(2)\n",
    "            file_2 = \"_\".join(file_1_split)\n",
    "\n",
    "            whole_path_1 = input_folder+file_1\n",
    "            whole_path_2 = input_folder+file_2\n",
    "\n",
    "            LAI,LAD,allangles,LA_correction_factors = whole_pipeline(whole_path_1,whole_path_2,visualize=False) \n",
    "\n",
    "        LAI_list.append([LAI])\n",
    "        LAD_list.append(LAD)\n",
    "        allangles_list.append(allangles)\n",
    "        LA_correction_factors_list.append(LA_correction_factors)\n",
    "        \n",
    "# storage in the final dataframe\n",
    "LAI_df = generate_df(files_list,LAI_list)\n",
    "LAI_df = LAI_df.rename(columns={'slice_1':'LAI'})\n",
    "\n",
    "LAD_df = generate_df(files_list,LAD_list)\n",
    "allangles_df = generate_df(files_list,allangles_list)\n",
    "LA_correction_factors_df = generate_df(files_list,LA_correction_factors_list)\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "    \n",
    "LAI_df.to_csv(output_folder+\"LAI_out.csv\",index=False)\n",
    "LAD_df.to_csv(output_folder+\"LAD_out.csv\",index=False)\n",
    "allangles_df.to_csv(output_folder+\"leaf_angles_out.csv\",index=False)\n",
    "LA_correction_factors_df.to_csv(output_folder+\"cf_out.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f9edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
